---
title: "Tutorial: Toy Data Set"
output: rmarkdown::html_vignette
bibliography: rankrate.bib
vignette: >
  %\VignetteIndexEntry{tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

In this tutorial, we demonstrate the key functionality of the `rankrate` package on a toy data set first analyzed in @gallo2022new. The tutorial includes code for visualization of rankings and ratings, as well as demonstration of functions for model estimation and inference. We begin by loading necessary packages.

```{r warning=FALSE,message=FALSE}
library(rankrate)
library(pander) # creating nice tables
library(reshape2) # data reformatting
library(ggplot2) # creating nice figures
```

## Exploratory Data Analysis

We now load the `ToyData1` data set, which is included in the `rankrate` package. The data set includes `r nrow(ToyData1$rankings)` judges who asses `r ncol(ToyData1$rankings)` objects with rankings and ratings. The rankings are complete rankings of all objects, and the ratings are integers between 0 (best) and `r ToyData1$M` (worst).

```{r}
data("ToyData1")
```

### Visualizing rankings

Let's start by displaying rankings from the toy data set in tabular and graphical form. 

```{r warning=FALSE, fig.asp = 0.7, out.width="90%",dpi=300}
rankings_table <- as.data.frame(ToyData1$rankings)
rownames(rankings_table) <- paste0("Judge ",1:16)
names(rankings_table) <- paste0("Rank ",1:3)
pander(rankings_table)
rankings_long <- melt(ToyData1$rankings)
names(rankings_long) <- c("Judge","Rank","Proposal")
ggplot(rankings_long,aes(x=Proposal,fill=factor(Rank)))+theme_bw(base_size=6)+
  geom_bar()+scale_fill_manual(values=c("#31A354","#A1D99B","#E5F5E0"))+
  labs(fill="Rank",y="Count")+ggtitle("Ranks by Proposal")+
  theme(legend.position = c(.8,.9),legend.direction = "horizontal",
        panel.grid = element_blank())
```

### Visualizing ratings

Let's start by displaying rankings from the toy data set in tabular and graphical form. 

```{r warning=FALSE, fig.asp = 0.7, out.width="90%",dpi=300}
ratings_table <- as.data.frame(ToyData1$ratings)
rownames(ratings_table) <- paste0("Judge ",1:16)
names(ratings_table) <- c("Proposal: 1",2:3)
set.alignment("right")
pander(ratings_table)
ratings_long <- melt(ToyData1$ratings)
names(ratings_long) <- c("Judge","Proposal","Rating")
ggplot(ratings_long,aes(x=factor(Proposal),y=Rating))+theme_bw(base_size=6)+
  geom_boxplot(color="gray")+geom_jitter(height=0,width=0.4,alpha=0.75)+
  labs(x="Proposal",y="Rating")+ggtitle("Ratings by Proposal")+
  theme(panel.grid = element_blank())
```






## Estimation

Now, let's fit a Mallows-Binomial model to our toy dataset. Given the relatively small size of the data, we will use the exact MLE search method, "ASTAR". 

```{r}
MLE_mb <- fit_mb(rankings=ToyData1$rankings,ratings=ToyData1$ratings,M=ToyData1$M,method="ASTAR")
data.frame(Parameter=c("Consensus Ranking, pi_0",
                       "Object Quality Parameter, p",
                       "Consensus Scale Parameter, theta"),
           MLE=c(paste0(MLE_mb$pi0,collapse="<"),
                 paste0("(",paste0(MLE_mb$p,collapse=","),")"),
                 round(MLE_mb$theta)))
```

## Inference

Furthermore, we can bootstrap confidence intervals using the `ci_mb` function. We plot the confidence intervals for the object quality parameters.

```{r, fig.asp = 0.7, out.width="90%",dpi=300}
CI_mb <- ci_mb(rankings=ToyData1$rankings,ratings=ToyData1$ratings,M=ToyData1$M,
               interval=0.95,nsamples=200,method="ASTAR")
plot_p <- as.data.frame(cbind(1:3,MLE_mb$p,t(CI_mb$ci[,1:3])))
names(plot_p) <- c("Proposal","PointEstimate","Lower","Upper")
ggplot(plot_p,aes(x=Proposal,y=PointEstimate,ymin=Lower,ymax=Upper))+
  geom_point()+geom_errorbar()+ylim(c(0,1))+theme_bw()+
  labs(x="Proposal",y="Estimated p (95% CI)")+
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank())
```

## References
